# Local Government in the Context of COVID-19 : Using Natural Language Processing to analyze discourse on Twitter across four U.S. Cities

## Intro
This Python code is created to understand discussions on Twitter around local governments during the COVID-19 pandemic. Analyses were conduced on Twitter data collected from four U.S. cities: New York City, Los Angeles, San Diego, and Detroit. 
Research Questions include:
What are the topics of conversation around local government? (LDA topic modeling),
How do the topics of tweets differ between the four cities? (PMI word clouds), and 
What are the sentiments of Tweets regarding local governments? (sentiment analysis). 

## Technology
Project is created with:
* Python Version 3.8
* Spyder Version 4.1.4

## Abstract
The COVID-19 pandemic has attuned citizens toward their local governments in the midst of local outbreaks and city-wide public health orders. However, little research has been done to understand the intersection of local government and COVID-19 from the perspectives of the citizens. This study utilizes Natural Language Processing tools (topic analysis, point mutual information analysis, and sentiment analysis) to understand local discourse on COVID-19 and local government in New York City, Los Angeles, Detroit, and San Diego. New York City emerged as the city discussing COVID-19 in relation to their local government the most followed by San Diego, Los Angeles, then Detroit. Topic Analysis indicated variant reactions toward the pandemic with New York City and Detroit topics having more urgency and specificity (i.e., the Rikers Island outbreak and the Detroit Police Department outbreak) while Los Angeles and San Diego showing more general themes (i.e., testing, face masks, symptoms) in preparation for the virus.  Three of the four cities showed a majority of negative leaning sentiments in the local government tweets, with Detroit being the only city with higher rates of positive tweets than negative. Results of this study can be used to inform local governments, researchers, and community members of the themes and sentiments within COVID-19 at the local level.


## Data and Methods
### Datasets
The datasets used in this study are a subset of a larger collection of COVID-19 related datasets collected by San Diego State University's Center for Human Dynamics in the Mobile Age (HDMA Center). The data was collected from Twitter using Twitter’s public API. Each of the datasets were collected between the dates March 17, 2020 and April 10, 2020. The keywords used to collect these data included: “coronavirus”, “COVID-19”, “nCoV”, “quarantine”, “pandemic”, “Wuhan”, and “covid”. While only four datasets will be used in this study, a total of nineteen datasets were collected on nineteen different U.S. cities. In order to collect tweets from specific cities, the researchers at the HDMA Center used the radius method, which returns tweets by users located within a given radius of a specified latitude/longitude (Twitter, 2020).

The datasets selected for this study include New York City, Los Angeles, Detroit, and San Diego. These cities were selected based on the criterion that they exhibit either or both of the following characteristics: 1) the city was among those hardest hit at the time of data collection (March – April) or, 2) the city represents densely populated areas which have been shown to be common COVID-19 hot spots. According to the cities’ publicly available data dashboards, both New York City and Detroit were hard hit with cases and deaths during March-April. While Los Angeles and San Diego did not experience as extreme effects in the early months of the virus, these cities’ COVID-19 tracking dashboards show an increase of cases later in the year (NYC Health, 2020; Detroit Health Department, 2020; County of Los Angeles Public Health, 2020; County of San Diego, 2021). According to U.S. Census Bureau’s population estimates for 2019, each of the cities populations are estimated as follows: New York City: 8,336,817, Los Angeles: 3,979,576, San Diego: 3,338,330, and Detroit: 670,031 (U.S. Census Bureau, 2019).

These four cities are located in states that also have varying levels of local autonomy according to Wolman et al.’s Local Autonomy Factor Score (2008). In this factor scale, New York state is ranked the highest (rank: 1, factor score: 0.845), California is ranked near the median (rank: 26, factor score: 0.043), and Michigan is rated at the low end of the second quartile (rank: 34, factor score: -0.175) (Figure 2).  Wolman’s factor scores do not include city level scores as local autonomy is determined at the state level. While it is possible for cities within a state to have differing types of local autonomy, the factor score takes into account seven root dimensions (i.e., local government importance, discretion, structural and functional responsibility, fiscal discretion limits, unconstrained revenue, capacity, and diversity of revenue sources) which are intended to cover a variety of variabilities within a state. Therefore, in this study we used Wolman’s scoring of each of the three cities’ respective states (i.e., New York City, New York; Los Angeles, California; San Diego, California; Detroit, Michigan) to determine their factor scores.

These four datasets were further refined in order to target tweets related to local government. This was done by mining the datasets for tweets including the following keywords: the city’s twitter handle (i.e., “@nycgov” “@LACity”, “@CityofSanDiego”, “@CityofDetroit”), the mayor’s names (i.e., “De Blasio”, “Garcetti”, “Faulconer”, “Duggan”), the mayor’s official twitter handle (i.e., “@NYCMayor”, “@MayorOfLA”, “@SDMayorsOffice”, “@MayorMikeDuggan”), the city’s official public health twitter handle (i.e., “@nycHealthy”, “@lapublichealth”, “@SDCountyHHSA”, “@DetHealth”), and if available, the county’s official twitter handle (i.e., “@CountyofLA”, “@SanDiegoCounty”, “@waynecountymi”). Note that the counties that comprise New York City do not have twitter accounts. 

### Analysis
Analysis of data began by conducting descriptive and inferential statistics on each city separately to understand the baselines of the given data as well as to compare the datasets to the greater population. After this, as exemplified by Park and Tsou (2020), this study analyzed public discourse using a variety of Natural Language Processing (NLP) methods in order to gain a fuller picture of each of the locations. Specifically, the evaluation of the four cities included three levels of content analyses:  1. Topic modeling, 2. Point Mutual Information (PMI) analysis, and 3. Sentiment Analysis. 
Topic modeling is a form of unsupervised modeling that allows researchers to discover word clusters or “topics” within a body of text. The goal of a topic model is to concisely identify the themes in a given lexical dataset. The most common technique in topic modeling is Latent Dirichlet Allocation (LDA). LDA allows a body of text to be understood as a distribution of topics, and each topic a distribution of words. This study utilized the gensim library within Python to build and run LDA models on each of the four cities. 

The Point Mutual Information (PMI) method takes content analysis a step further by identifying words that are uniquely highlighted within certain locations. While a simple content analysis will highlight the most frequently used word, using PMI scores will highlight words that are used more under a given condition. The following equation shows the calculation of PMI where P(X) and P(Y) represent the probability of each word X an Y:

PMI(X,Y) = log ((P(X,Y)/P(X) P(Y))

In this study, the condition given for the PMI analysis will be the city of the tweet. Therefore, following the methods exemplified in Park and Tsou (2020), the PMI formula was modified to show Wordcity as a given word in a given city, and Wordtotal as the total uses of the word in the corpus. Further, Ncity represents the total number of related words in the city with Ntotal showing the total number of words in the entire corpus. Therefore, the formula used in this study is as follows:

PMI(city, total) = log2((Wordcity * Ntotal)/(Wordtotal * Ncity))

The third round of content analysis involved a sentiment analysis of each of the three city’s tweets. This type of analysis is conducted in order to gauge the abstract opinions of a given tweet. Sentiment analysis functions by classifying a text into emotional, opinionated, or idea-based groups. In the context of COVID-19, conducting a sentiment analysis on polarity of each city enabled a deeper understanding of local citizens’ reactions to their local governments. Using the Textblob Library in Python, this study was able to return two properties, 1. polarity, and 2. subjectivity for every given tweet in the three city’s corpus’. Polarity is produced on a scale from -1.00 to 1.00, where a score below 0.00 indicates a negative tone and a score above 0.00 indicates a positive tone. Subjectivity is produced on a scale from 0.00 to 1.00 where a score approaching 0.00 can be understood as more object and a score approaching 1.00 can be understood as more subject. 

## Results
In order to inform the local knowledge aspect of Adam’s decentralization theory, descriptive statistics were first run to understand how many citizens are participating in public discourse on local government in regard to the various levels of authority as well as in comparison to the larger conversations happening around COVID-19 during March to April 2020. To gain the clearest understanding of public discourse, tweets produced from the local government sources themselves were removed. In proportion to all of the tweets collected on COVID-19 between March 17, 2020 and April 10, 2020, New York City showed the most discussion on local government agencies (1.62%), followed by San Diego (0.94%), Los Angeles (0.87%), and Detroit (0.41%).

After this, the local government tweets were further narrowed to exclude re-tweets in order to understand those tweets that were most likely to be directly addressing the government agencies. The majority of New York City, Los Angeles, and Detroit users were tweeting at or about their mayors within the local government tweets (83.28%, 80.81%, and 75.34% respectively). In contrast, San Diego users were focused more on the county’s twitter handle (76.25%).

Next the LDA model was run in order to more specifically identify the themes within the public discourse on local governments. During these analyses, retweets were included to ensure trending topics would be identified. Basic tuning was performed to find the optimal metrics (coherence and perplexity) for the LDA model within the abilities of the computational power available for the large datasets. Beyond the balance for complexity and perplexity, overall understandability of the topics was taken into account to find the best fitting parameters for the LDA models. Major topics for New York City included face masks, Rikers Island (a New York prison facility that was suffering from a fast-spreading COVID-19 outbreak), stay-at-home orders, thankful messages (directed toward New York City’s fire department, EMTs, and medical professionals), and political and social leaders (including Sean Hannity, President Trump, Governor Cuomo, and Thomas Frieden) (Appendix Table 1). Los Angeles’ five topics included COVID-19 testing, face masks, stay-at-home orders, cases/hospitalizations/deaths, and COVID-19 symptoms/vulnerabilities (Appendix Table 2). Detroit’s topics included the COVID-19 outbreak within the city’s Police Department, COVID-19 testing updates, small businesses/local community, and first responders/essential workers (Appendix Table 3). San Diego’s topics included city news, stay-at-home orders, COVID-19 updates, face masks, and social distancing.

The next step involved generating PMI scores for the tweets within each of the four city’s datasets. This step evaluated the major words that occurred uniquely within each of the cities compared to the words mentioned in all of the three areas combined. Therefore, compared to the LDA topic analysis, the PMI analysis shows different themes that emphasize the specific contexts of each of the cities. For example, New York City’s PMI results showed the word “beaches” as a frequently used in the city’s tweets (Figure 4a). Most likely this is due to the closure of New York City’s beaches as well as Mayor de Blasio’s announcement that there was no plan to reopen beaches in April (Marsh & Musumeci, 2020). Words of note in each of the cities include “beaches”, “chronic”, and “condition” for New York City, “mild”, “lack”, and “missed” for Los Angeles, “releasing”, “missed”, and “protective” for San Diego, and “@mcmuckraker”, “@cferretti”, and “@freep” for Detroit.

Finally, the sentiment analyses were run using TextBlob to create a polarity and subjectivity score for each tweet. The sentiment analysis holds the most value in interpreting the overall tone or feelings of social media users in comparison to the LDA and PMI analyses which only evaluate the topics and themes of discussion. Once again, re-tweets were removed in order to understand the polarity and subjectivity of tweets most likely to be directed at local government agencies. Slightly over half of the New York City and Los Angeles tweets showed negative sentiments (53.76% and 54.33% respectively). San Diego demonstrated a similar amount for both positive (50.50%) and negative (49.50%) tweets. Detroit was the only city that showed more positive tweets (54.89%) than negative (45.11%).

Subjective and objective tweets were similarly proportioned across the four cities with objective tweets constituting between 70.71% and 76.01% of the local government tweets across cities. Subjective tweets fell between 23.99% to 29.29% in each of the cities, showing objectivity to be a dominant characteristic across all four of the cities.

To further analyze the specificities within local government, sentiment analyses were also run on only the mayoral keywords within each of the cities. Results showed that De Blasio, Garcetti, and Faulconer had more tweets with negative sentiments than positive. Similarly to the overall positivity results, Duggan was the only mayor that showed more positive sentiment tweets (55.73%) than negative (44.27%).

Subjectivity analyses was also run on the mayors showing that, across all cities, the majority of tweets regarding their local mayors leaned toward objectivity. However, Faulconer showed the least amount of subjectivity with under 20% of subjective content around him compared to the other three mayors which each had more than 27% of subjective content.










